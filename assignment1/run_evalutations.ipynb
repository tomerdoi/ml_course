{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This cell is for Colab initialization. To install the wandb api and login into it.\n",
        "# This is for single use.\n",
        "! pip3 install wandb\n",
        "! wandb login"
      ],
      "metadata": {
        "id": "54eqeTc3fHzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "i9JPgdR4fFP3"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelBinarizer, KBinsDiscretizer, OneHotEncoder, LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from bagging_id3 import MyBaggingID3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets\n",
        "\n",
        "We used 5 online datasets:\n",
        "- Breast Cancer coimbra\n",
        "- breast cancer wisconsin\n",
        "- ionosphere\n",
        "- spectf\n",
        "- algerian forest fires"
      ],
      "metadata": {
        "id": "hV3lgVQnZhIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_breast_cancer_coimbra():\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv')\n",
        "    # Preprocess the data\n",
        "    X = df.drop('Classification', axis=1)\n",
        "    y = df['Classification']\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "    kb = KBinsDiscretizer(n_bins=2, encode='ordinal', strategy='quantile')\n",
        "    X = kb.fit_transform(X)\n",
        "    return X, y\n",
        "    \n",
        "def preprocess_algerian_forest_fires():\n",
        "    lb = LabelEncoder()\n",
        "    df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00547/'\n",
        "                      'Algerian_forest_fires_dataset_UPDATE.csv', skiprows=1, nrows=122)\n",
        "\n",
        "    def convert_class_value(value):\n",
        "        if 'not' in value:\n",
        "            return 0\n",
        "        else:\n",
        "            return 1\n",
        "    # apply the function to the class column and assign the result to a new column 'class_num'\n",
        "    df['Classes  '] = df['Classes  '].apply(convert_class_value)\n",
        "    df = df.dropna()\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1]\n",
        "    n_bins = 2\n",
        "    encode = 'ordinal'\n",
        "    strategy = 'uniform'\n",
        "    # Discretize the non-binary features only\n",
        "    kb = KBinsDiscretizer(n_bins=n_bins, encode=encode, strategy=strategy)\n",
        "    X_binned = kb.fit_transform(X)\n",
        "    y = lb.fit_transform(y)\n",
        "    return X_binned, y\n",
        "    \n",
        "def preprocess_breast_cancer_wisconsin():\n",
        "    df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/'\n",
        "                      'wdbc.data', header=None)\n",
        "    X = df.iloc[:, 2:]\n",
        "    y = df.iloc[:, 1]\n",
        "    n_bins = 2\n",
        "    encode = 'ordinal'\n",
        "    strategy = 'uniform'\n",
        "    # Discretize the non-binary features only\n",
        "    kb = KBinsDiscretizer(n_bins=n_bins, encode=encode, strategy=strategy)\n",
        "    X_binned = kb.fit_transform(X)\n",
        "    lb = LabelBinarizer()\n",
        "    y = lb.fit_transform(y)\n",
        "    return X_binned, y\n",
        "\n",
        "def preprocess_ionosphere():\n",
        "    df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data',\n",
        "                      header=None)\n",
        "    n_bins = 2\n",
        "    encode = 'ordinal'\n",
        "    strategy = 'uniform'\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1]\n",
        "    # Identify binary features based on the number of unique values\n",
        "    bin_feats = np.where(np.apply_along_axis(lambda x: len(np.unique(x)) == 2, 0, X))[0]\n",
        "    nonbin_feats = np.setdiff1d(np.arange(X.shape[1]), bin_feats)\n",
        "\n",
        "    # Discretize the non-binary features only\n",
        "    if len(nonbin_feats) > 0:\n",
        "        kb = KBinsDiscretizer(n_bins=n_bins, encode=encode, strategy=strategy)\n",
        "        X_binned_nonbin = kb.fit_transform(X.loc[:, nonbin_feats])\n",
        "        X_binned = np.concatenate((X_binned_nonbin, X.loc[:, bin_feats]), axis=1)\n",
        "    else:\n",
        "        X_binned = X\n",
        "    lb = LabelBinarizer()\n",
        "    y = lb.fit_transform(y)\n",
        "    return X_binned, y\n",
        "\n",
        "def preprocess_spectf():\n",
        "    df_train = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/spect/SPECT.train',\n",
        "                            header=None)\n",
        "    df_test = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/spect/SPECT.test',\n",
        "                          header=None)\n",
        "    df = pd.concat([df_train, df_test])\n",
        "    X = df.iloc[:, 1:].values\n",
        "    y = df.iloc[:, 0]\n",
        "    return X, y\n",
        "\n",
        "datasets = {'breast-cancer': preprocess_breast_cancer_coimbra, 'algerian-forest-fires': preprocess_algerian_forest_fires, 'breast-cancer-wisconsin': preprocess_breast_cancer_wisconsin, 'ionosphere': preprocess_ionosphere, 'spectf': preprocess_spectf}"
      ],
      "metadata": {
        "id": "XbBjD-1d8PO4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating\n",
        "\n",
        "We used 3 models to compare between - Our implementation, a single `DecisionTreeClassifier`, and a `BaggingClassifier` (the last 2 are from `sklearn` package). "
      ],
      "metadata": {
        "id": "n_7-DukPZ4xs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "def evaluate_model(ds_name, X, y, n_estimators=250, max_samples=1.0, max_features=0, max_depth=100):\n",
        "    try:\n",
        "        if not max_features:\n",
        "            max_features = round(1 / np.sqrt(X.shape[1]), 2)\n",
        "        my_bagging_id3 = MyBaggingID3(n_estimators=n_estimators, max_samples=max_samples, max_features=max_features,\n",
        "                                      max_depth=max_depth)\n",
        "        dtc = DecisionTreeClassifier(max_depth=max_depth, max_features=max_features)\n",
        "        bc = BaggingClassifier(base_estimator=dtc, n_estimators=n_estimators, max_samples=max_samples,\n",
        "                                max_features=max_features)\n",
        "        # Define the evaluation metrics\n",
        "        scoring = {\n",
        "            'accuracy': 'accuracy',\n",
        "            'precision': 'precision',\n",
        "            'recall': 'recall',\n",
        "            'f1_score': 'f1',\n",
        "            'roc_auc_score': 'roc_auc'\n",
        "        }\n",
        "        # Define the cross-validation procedure\n",
        "        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
        "        # Evaluate the models\n",
        "        models = {'MyBaggingID3': my_bagging_id3, 'DecisionTreeClassifier': dtc, 'BaggingClassifier': bc}\n",
        "        \n",
        "        for name, model in models.items():\n",
        "            wandb.init(project=ds_name, name=name, config={\n",
        "              \"# Estimators\": n_estimators,\n",
        "              \"max_samples\": max_samples,\n",
        "              \"max_features\": max_features,\n",
        "              \"max_depth\": max_depth\n",
        "            })\n",
        "            for _ in range(2):\n",
        "                cv_results = cross_validate(model, X, y, cv=cv, scoring=scoring, return_train_score=False)\n",
        "                wandb.log({'fit_time': cv_results['fit_time'].mean(),\n",
        "                                  **{metric: cv_results['test_%s' % metric].mean() for metric in scoring}})\n",
        "            wandb.finish()\n",
        "    finally:\n",
        "        wandb.finish()"
      ],
      "metadata": {
        "id": "USnC67klfFP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, prep in datasets.items():\n",
        "  X, y = prep()\n",
        "  evaluate_model(name, X, y, max_depth=50)"
      ],
      "metadata": {
        "id": "-V-ZOCaTgxZe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}